---
title: "This week in Responsible AI: Apr 21, 2023"
date: 2023-04-20T13:04:09-05:00
draft: true
---

## General

- NeurIPS announces a [code of ethics](https://blog.neurips.cc/2023/04/20/announcing-the-neurips-code-of-ethics/)

- [The Myth of Objective Data](https://thereader.mitpress.mit.edu/the-myth-of-objective-data/)

- [How](https://arxiv.org/abs/2304.07249) do you design an AI ethics board that actually works?

## Law/Policy

- [How We Think About Copyright and AI Art](https://www.eff.org/deeplinks/2023/04/how-we-think-about-copyright-and-ai-art-0)

- [Italy gives OpenAI initial to-do list for lifting ChatGPT suspension order](https://techcrunch.com/2023/04/12/chatgpt-italy-gdpr-order/?utm_source=substack&utm_medium=email&guccounter=1)

- [OpenAI could soon be banned from the entire EU for violating GDPR](https://www.technologyreview.com/2023/04/19/1071789/openais-hunger-for-data-is-coming-back-to-bite-it/?truid=&utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=Active%20Qualified&utm_content=04-19-2023&mc_cid=8f246dd37f&mc_eid=f14ac890df)

- Drake deepfake raises copyright issues: [1](https://www.bbc.com/news/entertainment-arts-65298834?utm_source=substack&utm_medium=email), [2](https://www.theverge.com/2023/4/19/23689879/ai-drake-song-google-youtube-fair-use)

- [European privacy watchdog creates ChatGPT task force](https://www.reuters.com/technology/european-data-protection-board-discussing-ai-policy-thursday-meeting-2023-04-13/?utm_source=substack&utm_medium=email)

- [Resources](https://genlaw.github.io/resources.html) on legal issues raised by Generative AI

- [The Developing Law of AI Regulation: A Turn to Risk Regulation](https://www.lawfareblog.com/developing-law-ai-regulation-turn-risk-regulation)

- China's draft document on regulating generative AI: [1](https://www.insideprivacy.com/artificial-intelligence/china-proposes-draft-measures-to-regulate-generative-ai/), [2](https://twitter.com/mmitchell_ai/status/1647692403753783296?s=20)


## Transparency

- [Diagnosing AI Explanation Methods with Folk Concepts of Behavior](https://arxiv.org/abs/2201.11239)

## AI Harms

- [Study finds that companies like Uber and Amazon engage in 'algorithmic wage discrimination'](https://www.cbsnews.com/news/algorithmic-wage-discrimination-artificial-intelligence/)

- [The algorithm that blew up Italy's school system](https://algorithmwatch.org/en/algorithm-school-system-italy/)

- [Large-scale AI models consume a lot of water---but carbon reduction and water conservation are in tension with each other.](https://themarkup.org/hello-world/2023/04/15/the-secret-water-footprint-of-ai-technology)

- [GPT-4 is a Risky Dependency for FOSS Projects](http://www.alysbrooks.com/gpt-4-is-a-risky-dependency-for-foss-projects.html)

- [Meta's Oversight Board urges Meta "to commission an impact assessment with a focus on how design features like Facebook's News Feed recommendation algorithms can amplify dangerous health-related misinformation."](https://www.theverge.com/2023/4/20/23690853/meta-oversight-board-report-investigation-covid-amplifying-misinformation)

## Power

- [Digital Sovereignty: the Case of Contact Tracing Apps](https://public.digital/2023/04/18/digital-sovereignty-the-case-of-contact-tracing-apps)

- [Generative AI risks concentrating Big Tech's power. Here's how to stop it.](https://www.technologyreview.com/2023/04/18/1071727/generative-ai-risks-concentrating-big-techs-power-heres-how-to-stop-it/?utm_campaign=site_visitor.unpaid.engagement&utm_source=Twitter&utm_medium=tr_social)

# Privacy

- [why US 'spy-tech' firm Palantir processes NHS data](https://www.opendemocracy.net/en/palantir-nhs-covid-datastore-foundry-peter-thiel/)


## Generative models

- [Google employees begged Google not to release Bard](https://www.theverge.com/2023/4/19/23689554/google-ai-chatbot-bard-employees-criticism-pathological-liar)

- ['ChatGPT was more likely to express "discriminatory opinions" and stereotype specific ethnic groups and countries when assigned a persona.'](https://techcrunch.com/2023/04/12/researchers-discover-a-way-to-make-chatgpt-consistently-toxic/?utm_source=substack&utm_medium=email)

- [Why scientists should avoid proprietary generative AI models](https://www.nature.com/articles/d41586-023-01295-4)

- [Stop Treating AI Models Like People](https://garymarcus.substack.com/p/stop-treating-ai-models-like-people?utm_source=twitter&sd=pf)