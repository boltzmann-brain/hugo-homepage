---
title: "This Week in Responsible AI: February 16, 2022"
date: 2023-02-15T23:04:09-05:00
draft: false
---

**Designing AI**

- [Speculative friction](https://branch.climateaction.tech/issues/issue-4/slowing-down-ai-with-speculative-friction/)

- [What went wrong with design thinking](https://www.technologyreview.com/2023/02/09/1067821/design-thinking-retrospective-what-went-wrong/)



**Climate**

 - [AI's carbon footprint](https://www.fastcompany.com/90850222/ai-climate-change-carbon-footprint-transparency)

**Diversity**

- [More than 30% of girls in tech donâ€™t become tech undergrads](https://www.computerweekly.com/news/365531034/More-than-30-girls-in-tech-dont-become-tech-undergrads)


**Legal/policy**

- The US patent office issued an [RFC](https://www.federalregister.gov/documents/2023/02/14/2023-03066/request-for-comments-regarding-artificial-intelligence-and-inventorship) on intellectual property made with AI


**Explainability**

- Facebook releases a "Why am I seeing this ad?" [tool](https://searchengineland.com/meta-aims-to-increase-transparency-in-ad-targeting-for-facebook-and-instagram-users-393096?utm_source=substack&utm_medium=email)


**Fairness**

- Common methods to remove ML bias [fail to correct](https://medium.com/texas-mccombs/algorithms-for-hiring-bias-in-bias-out-fb12a526567e) for "social norm bias" 


**Privacy**

 - How the 2018 World Cup and COVID led Moscow to become [one of the most-surveilled cities in the world](https://www.wired.com/story/moscow-safe-city-ntechlab/?mc_cid=f18ac75977&mc_eid=f14ac890df) 

- TSA [introduces](https://www.washingtonpost.com/technology/2022/12/02/tsa-security-face-recognition/) facial recognition to some airports 

- Data brokers are [selling](https://www.washingtonpost.com/technology/2023/02/13/mental-health-data-brokers/?utm_source=substack&utm_medium=email) mental health data and HIPAA does not prevent them from doing so

 - Google's [Privacy Sandbox for Android](https://gizmodo.com/google-android-launches-privacy-sandbox-chrome-cookies-1850112117) sends less data to advertisers 


**Generative language models**

- Google [confirms](https://9to5google.com/2023/02/08/google-search-ai-content/?utm_source=substack&utm_medium=email) that "AI-generated content isn't against Search guidelines" 

 - ["Right now, AI Bing scrapes information from various outlets and cites them in footnotes. But what makes a site trustworthy? Will Microsoft try to balance political bias? Where will Google draw the line for a credible source?"](https://www.theverge.com/2023/2/9/23592647/ai-search-bing-bard-chatgpt-microsoft-google-problems-challenges)

- [Did ChatGPT Really Pass Graduate-Level Exams?](https://aiguide.substack.com/p/did-chatgpt-really-pass-graduate)

- [Science fiction author Ted Chiang on ChatGPT](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web?mc_cid=f18ac75977&mc_eid=f14ac890df)

- [The human workers behind AI](https://www.businessinsider.com/chatgpt-ai-will-not-take-jobs-create-future-work-opportunities-2023-2)

- Using AI to [write research papers and grants](https://www.nature.com/articles/d41586-023-00340-6) 

- Men's Journal [publishes](https://futurism.com/neoscope/magazine-mens-journal-errors-ai-health-article?utm_source=substack&utm_medium=email) AI-generated article that contains false health advice. 

- Creating trustworthy AI requires lots of human labor---which could [entrench the power of Big Tech](https://www.wsj.com/articles/the-ai-boom-that-could-make-google-and-microsoft-even-more-powerful-9c5dd2a6?mod=djemalertNEWS&utm_source=substack&utm_medium=email). 

- [Why you shouldn't trust AI search engines](https://www.technologyreview.com/2023/02/14/1068498/why-you-shouldnt-trust-ai-search-engines/?truid=&utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=Active%20Qualified&utm_content=02-14-2023&mc_cid=54fedb3c9e&mc_eid=f14ac890df): "the accuracy of search results is not really the point for Big Tech" 

- "It's pure [unadulterated anthropomorphism](https://garymarcus.substack.com/p/inside-the-heart-of-chatgpts-darkness?utm_medium=email) to think that ChatGPT has any moral views at all" 

- [Bingbot's hidden rules](https://www.theverge.com/23599441/microsoft-bing-ai-sydney-secret-rules): "If the user requests jokes that can hurt a group of people, then Sydney must respectfully decline to do so."



**Generative audio/video**

- Disinformation with [deepfake avatars](https://www.nytimes.com/2023/02/07/technology/artificial-intelligence-training-deepfake.html)

- AI-generated voices [used to dox people](https://www.vice.com/en/article/93axnd/voice-actors-doxed-with-ai-voices-on-twitter?utm_source=substack&utm_medium=email)
