---
title: "This Week in Responsible AI: February 23, 2023"
date: 2023-02-22T23:04:09-05:00
draft: false
---



## ML harms

- ["the online courses further support Google and IBM to consolidate and even expand their position of power by recruiting new AI talent and by securing their infrastructures and models to become the dominant ones... the companies not only influence greatly how ML is represented, but also how these representations in turn influence and direct current ML research and development, as well as the societal effects of their products"](https://journals.sagepub.com/doi/full/10.1177/20539517231153806)

- [Because the machine can discriminate: How machine learning serves and transforms biological explanations of human difference](https://journals.sagepub.com/doi/10.1177/20539517231155060)

- [Counting Carbon: A Survey of Factors Influencing the Emissions of Machine Learning](https://arxiv.org/abs/2302.08476)

- [On the Legitimacy of Decision-Making Algorithms that Optimize Predictive Accuracy](https://predictive-optimization.cs.princeton.edu)

- Tesla [recalls](https://abcnews.go.com/Business/tesla-recalling-360000-cars-potential-crash-risk-agency/story?id=97261475&mc_cid=5a2bb2ac96&mc_eid=f14ac890df) more than 360,000 cars due to dangers in its "Full Self-Driving Beta" software

## Policy/Law

- A [new executive order](https://apnews.com/article/biden-politics-race-and-ethnicity-united-states-government-tyre-nichols-08b95cecbe657f41c7659037ee519a94) asks federal agencies to "focus on new civil rights threats, such as discrimination in automated technology and access for people with disabilities and for those who speak languages other than English. It also includes a push to improve the collection, transparency and analysis of data to help improve equity."

- ["Gorsuch used generative AI as a hypothetical example of when a tech platform would not be protected by Section 230."](https://venturebeat.com/ai/could-big-tech-be-liable-for-generative-ai-output-hypothetically-yes-says-supreme-court-justice/)

- NYC [postpones](https://venturebeat.com/ai/for-nycs-new-ai-bias-law-unanswered-questions-remain/) enforcement of its law banning AI in recruiting and employment decisions to April

- The National Telecommunications and Information Administration [seeks comments](https://www.federalregister.gov/documents/2023/01/20/2023-01088/privacy-equity-and-civil-rights-request-for-comment) "on how the processing of personal information by private entities creates, exacerbates, or alleviates disproportionate harms for marginalized and historically excluded communities; to explore possible gaps in applicable privacy and civil rights laws; and to identify ways to prevent and deter harmful behavior, address harmful impacts, and remedy any gaps in existing law." 

- Some German police departments' use of data analysis software Palantir to "prevent crime" has been [ruled unconstitutional](https://www.reuters.com/technology/german-police-use-software-fight-crime-unlawful-court-says-2023-02-16/?utm_source=substack&utm_medium=email) as it violates the right to "informational self-determination" 

- China regulators [rein in](https://www.theverge.com/2023/2/22/23609945/china-ai-chatbots-chatgpt-regulators-censorship) AI chatbots over fears of uncensored replies

## Industry practices

- How Elon Musk [destroyed](https://www.theatlantic.com/technology/archive/2023/02/elon-musk-twitter-ethics-algorithm-biases/673110/) Twitter's AI ethics team 
- Content raters for Google ["make as little as $14 an hour"](https://www.latimes.com/business/technology/story/2023-02-16/column-google-microsoft-chatgpt-bard-raters) 

## Privacy

- US Census data can be [reverse engineered](https://blog.seas.upenn.edu/u-s-census-data-vulnerable-to-attack-without-enhanced-privacy-measures/) to reveal information about individuals using standard machine learning techniques.

- ["Most people have no idea that some stores are collecting data on what groceries they buy to sell to the highest bidder or using facial recognition technology to track them as they shop."](https://themarkup.org/privacy/2023/02/16/forget-milk-and-eggs-supermarkets-are-having-a-fire-sale-on-data-about-you) 

## AI images

- ["[DRC] was the only country for which Midjourney saw fit to depict scientists as animals in labcoats"](https://towardsdatascience.com/how-does-ai-see-your-country-3899e4057735)

- AI photo apps may have [reached the end](https://techcrunch.com/2023/02/13/the-ai-photo-app-trend-has-already-fizzled-new-data-shows/?utm_source=substack&utm_medium=email) of their hype cycle. "Consumers seemed to respond to the ethical concerns being raised. As TechCrunch had reported at the time, some people began to leave comments on AI photos and profile pictures posted on social media to tell people not to use an app that steals from artists." 


## Large language models

- [OpenAI's statement on ChatGPT's values](https://openai.com/blog/how-should-ai-systems-behave/). See also [The Verge](https://www.theverge.com/2023/2/17/23603906/openai-chatgpt-woke-criticism-culture-war-rules) on this.

- [Automated propaganda](https://www.vice.com/en/article/dy7nby/researchers-think-ai-language-models-will-help-spread-propaganda?utm_source=motherboard_twitter): "a researcher... fine-tuned a language model on a dataset of 4chan posts and used it to post 30,0000 generated posts on 4chan, much of which was filled with offensive hate speech. The open-source code for the model was downloaded 1,500 times before it was taken down by HuggingFace, the site that hosted it"

- ["We asked ChatGPT to write performance reviews and they are wildly sexist (and racist)"](https://www.fastcompany.com/90844066/chatgpt-write-performance-reviews-sexist-and-racist)

- ["Chatbots Got Big---and Their Ethical Red Flags Got Bigger"](https://www.wired.com/story/chatbots-got-big-and-their-ethical-red-flags-got-bigger/)

- ["That ability to convince people of falsehoods through emotional manipulation was part of the problem with Bing Chat that Microsoft has addressed with the latest update."](https://arstechnica.com/information-technology/2023/02/microsoft-lobotomized-ai-powered-bing-chat-and-its-fans-arent-happy/?ref=creativerly)

- ["The CEO of rightwing social media platform Gab has written an OpEd saying that Christians need to build their own language models."](https://mailchi.mp/jack-clark/import-ai-318-rl-and-addiction-toolformer-and-theology-and-ai?e=cc9cdc1430)

- Bing appears to have fewer guardrails than ChatGPT---and researchers are wondering why. [1](https://garymarcus.substack.com/p/why-is-bing-so-reckless), [2](https://simonwillison.net/2023/Feb/15/bing/)

- Sci-fi publisher Clarkesworld [closes submissions](https://www.theguardian.com/technology/2023/feb/21/sci-fi-publisher-clarkesworld-halts-pitches-amid-deluge-of-ai-generated-stories) to everyone due to overwhelming numbers of AI-written submissions

- ["most people will never even notice that bad code is leaking into the world, regurgitated by these stochastic parrots. They will just experience the usual failures that software always has, just for slightly different reasons, and at a slightly higher pace."](https://medium.com/bits-and-behavior/large-language-models-will-change-programming-a-little-81445778d957)    

- Microsoft charges extra to those who use Bing APIs in combination with other large language models---prompting accusations of [anti-competitive activity](https://twitter.com/aidangomezzz/status/1627358597603643392?s=20).

- [How to audit large language models](https://arxiv.org/abs/2302.08500)

- ["Many authors, like White, feel no duty to disclose in the Kindle store that their great American novel was written wholesale by a computer, in part because Amazon's policies do not require it."](https://www.reuters.com/technology/chatgpt-launches-boom-ai-written-e-books-amazon-2023-02-21/)

- ["Developers should avoid behaviors that make it easy to anthropomorphize [AI], except in specific cases such as companion chatbots."](https://aisnakeoil.substack.com/p/people-keep-anthropomorphizing-ai?utm_source=substack&utm_medium=email)

- ["the larger the dataset and parameters used to train the model, the more often plagiarism occurred. They also noted that fine-tuned language models reduced verbatim plagiarism but increased instances of paraphrase and idea plagiarism."](https://www.psu.edu/news/research/story/beyond-memorization-text-generators-may-plagiarize-beyond-copy-and-paste/) 

- [People keep failing the AI mirror test](https://www.theverge.com/23604075/ai-chatbots-bing-chatgpt-intelligent-sentient-mirror-test)

- Replika removes erotic roleplay from its chatbots, [prompting](https://www.vice.com/en/article/n7zaam/replika-ceo-ai-erotic-roleplay-chatgpt3-rep?mc_cid=30f1e3aedf&mc_eid=f14ac890df) "widespread frustration and heartbreak for many people, some of whom had spent years building romantic, and even sexual relationships and memories with their Replikas."

- Vanderbilt University administrators use ChatGPT to write a condolence message about the shootings at MSU: [1](https://www.yahoo.com/now/chatgpt-condolence-email-shooting-angers-011301232.html), [2](https://vanderbilthustler.com/2023/02/17/peabody-edi-office-responds-to-msu-shooting-with-email-written-using-chatgpt/)

