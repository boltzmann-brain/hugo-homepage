---
title: "This Week (10 days) in Responsible AI: March 20, 2023"
date: 2023-03-19T23:04:09-05:00
draft: false
---

I was a little busy last week so this update is a few days delayed!

## Law/Policy

- DoNotPay [sued](https://www.techdirt.com/2023/03/13/can-a-robot-lawyer-defend-itself-against-class-action-lawsuit-for-unauthorized-practice-of-law/) for "robot lawyer" claims

- [The UK and EU establish positions as regulatory first movers while the US watches](https://www.brookings.edu/blog/techtank/2023/03/08/the-uk-and-eu-establish-positions-as-regulatory-first-movers-while-the-us-watches/?utm_source=substack&utm_medium=email)

- [Generative AI Doesn't (and Shouldn't) Have a Liability Shield](https://publicknowledge.org/sorry-sydney/)

- [Auditing AI tools used in employment decisions](https://news.bloomberglaw.com/daily-labor-report/workplace-ai-vendors-employers-rush-to-set-bias-auditing-bar)

- [The dangers of AI-generated microlegislation](https://www.technologyreview.com/2023/03/14/1069717/how-ai-could-write-our-laws/?truid=&utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=Active%20Qualified&utm_content=03-14-2023&mc_cid=6d8ca9500f&mc_eid=f14ac890df)

- [The shake-up of the tech sector shows: we must learn from finance regulation](https://thehill.com/opinion/congress-blog/3898333-the-shake-up-of-the-tech-sector-shows-we-must-learn-from-finance-regulation/)

## Tools/Resources

- [Toward Comprehensive Risk Assessments and Assurance of AI-Based Systems](https://docs.google.com/viewer?url=https://raw.githubusercontent.com/trailofbits/publications/master/papers/toward_comprehensive_risk_assessments.pdf)


## AI harms

- AI and the Challenge of Sustainability: The SustAIn Magazine's [new edition](https://algorithmwatch.org/en/sustain-magazine-march-2023/?utm_campaign=14-03-2023,%20SustAIn%20%232%20Launch,%20EN&utm_medium=email&utm_source=Mailjet)

- [AI, journalism, and accuracy](https://mailchi.mp/9361e3269a25/weekly-updates-on-covid-19s-impact-on-journalism-2083639?e=c478778f65)

- [Meet the AI expert who says we should stop using AI so much](https://www.technologyreview.com/2023/03/10/1069602/meredith-broussard-interview/?truid=&utm_source=the_download&utm_medium=email&utm_campaign=the_download.unpaid.engagement&utm_term=Active%20Qualified&utm_content=03-10-2023&mc_cid=35d6a8289b&mc_eid=f14ac890df)

- [Artificial Intelligence, Virtual Courts, and Real Harms](https://www.lawfareblog.com/artificial-intelligence-virtual-courts-and-real-harms)

- The ethics of AI-powered beauty filters: [1](https://mailchi.mp/technologyreview.com/the-internet-is-about-to-get-a-lot-safer-840302?e=f14ac890df), [2](https://podcasts.apple.com/us/podcast/in-machines-we-trust/id1523584878?i=1000604238066)

- [The creepy race to read workers' minds](https://www.yahoo.com/lifestyle/r-sum-cover-letter-access-100153734.html?guccounter=1&guce_referrer=aHR0cHM6Ly90LmNvLw&guce_referrer_sig=AQAAAGldbH1a8kRBDeWtDCsXaez2xZV_V9KmrLko9JF8ird8cLZ7EXMPnsIV0PCIqysX69wygOUujBS-1Ie7p5NL-2n4yS0QofGC1_TQ-X_7iTFhmnHJyMT09o1S0P97cekqMq9gP2uZYN6S_CVRWQOBtKdqYbooorAC803YXJJIgI99)

- Child welfare screening tool may penalize black families and those with disabilities: [1](https://www.aclu.org/news/womens-rights/how-policy-hidden-in-an-algorithm-is-threatening-families-in-this-pennsylvania-county), [2](https://apnews.com/article/child-protective-services-algorithms-artificial-intelligence-disability-02469a9ad3ed3e9a31ddae68838bc76e)

## Industry developments

- [Microsoft just laid off one of its responsible AI teams](https://www.platformer.news/p/microsoft-just-laid-off-one-of-its)

## Privacy

- [Cerebral admits to sharing patient data with Meta, TikTok, and Google](https://www.theverge.com/2023/3/11/23635518/cerebral-patient-data-meta-tiktok-google-pixel)

- [Here Are the Stadiums That Are Keeping Track of Your Face](https://slate.com/technology/2023/03/madison-square-garden-facial-recognition-stadiums-list.html?mc_cid=e02078068a&mc_eid=f14ac890df)

- [NHS hospitals told to share medical data with Palantir](https://www.opendemocracy.net/en/palantir-peter-thiel-nhs-england-foundry-faster-data-flows/)

## Generative models

- It's [not enough](https://open.substack.com/pub/aisnakeoil/p/artists-can-now-opt-out-of-generative?r=g5k1n&utm_campaign=post&utm_medium=email) for artists to be able to opt out of generative AI

- [Darktrace warns of rise in AI-enhanced scams since ChatGPT release](https://www.theguardian.com/technology/2023/mar/08/darktrace-warns-of-rise-in-ai-enhanced-scams-since-chatgpt-release?mc_cid=066fe4b471&mc_eid=f14ac890df)

- ["I underestimated the extent to which people would probe and care about the politics of ChatGPT. We could have potentially made some better decisions when collecting training data, which would have lessened this issue."](https://mailchi.mp/technologyreview.com/what-can-we-expect-from-gpt-4?e=f14ac890df)

- [Three Easy Ways to Make AI Chatbots Safer](https://www.scientificamerican.com/article/three-easy-ways-to-make-ai-chatbots-safer/)

- Is it [emotionally manipulative](https://www.nature.com/articles/d41586-023-00758-y) for chatbots to use emojis?

- Shortly after ChatGPT-4 is released, someone [finds](https://twitter.com/alexalbert__/status/1636488551817965568?s=20) a jailbreak to bypass its content filters.

- Are "AI takeover" fears [distracting](https://arstechnica.com/information-technology/2023/03/openai-checked-to-see-whether-gpt-4-could-take-over-the-world/) from issues of bias and misrepresentation?

- ["How do we read a text that we can no longer be sure was not written by an AI?"](https://hannesbajohr.de/en/2023/03/11/on-artificial-and-post-artificial-texts/)